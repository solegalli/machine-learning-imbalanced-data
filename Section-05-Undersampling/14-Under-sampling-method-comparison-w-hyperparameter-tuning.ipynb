{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a classifier with under-sampling, CV and hyperparameter tuning\n",
    "\n",
    "[Machine Learning with Imbalanced Data - Course](https://www.trainindata.com/p/machine-learning-with-imbalanced-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    CondensedNearestNeighbour,\n",
    "    TomekLinks,\n",
    "    OneSidedSelection,\n",
    "    EditedNearestNeighbours,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    AllKNN,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    NearMiss,\n",
    "    InstanceHardnessThreshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler_dict = {\n",
    "\n",
    "    'random': RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        replacement=False),\n",
    "\n",
    "    'cnn': CondensedNearestNeighbour(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_neighbors=1,\n",
    "        n_jobs=4),\n",
    "\n",
    "    'tomek': TomekLinks(\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4),\n",
    "\n",
    "    'oss': OneSidedSelection(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_neighbors=1,\n",
    "        n_jobs=4),\n",
    "\n",
    "    'enn': EditedNearestNeighbours(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4),\n",
    "\n",
    "    'renn': RepeatedEditedNearestNeighbours(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4,\n",
    "        max_iter=100),\n",
    "\n",
    "    'allknn': AllKNN(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=5,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4),\n",
    "\n",
    "    'ncr': NeighbourhoodCleaningRule(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4,\n",
    "        threshold_cleaning=0.5),\n",
    "\n",
    "    'nm1': NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=1,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4),\n",
    "\n",
    "    'nm2': NearMiss(\n",
    "        sampling_strategy='auto',\n",
    "        version=2,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4),\n",
    "\n",
    "    # we set up the instance hardness threshold\n",
    "    # with the same classifier that we intend to use in our data\n",
    "    'iht': InstanceHardnessThreshold(\n",
    "        estimator=RandomForestClassifier(\n",
    "            n_estimators=100, random_state=39, max_depth=3, n_jobs=4,\n",
    "        ),\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_jobs=4,\n",
    "        cv=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these datasets are baked into imbalanced-learn\n",
    "\n",
    "datasets_ls = [\n",
    "    'ecoli',\n",
    "    'optical_digits',\n",
    "    'satimage',\n",
    "    'pen_digits',\n",
    "    'abalone',\n",
    "    'sick_euthyroid',\n",
    "    'spectrometer',\n",
    "    'car_eval_34',\n",
    "    'isolet',\n",
    "    'us_crime',\n",
    "    'yeast_ml8',\n",
    "    'scene',\n",
    "    'libras_move',\n",
    "    'thyroid_sick',\n",
    "    'coil_2000',\n",
    "    'arrhythmia',\n",
    "    'solar_flare_m0',\n",
    "    'oil',\n",
    "    'car_eval_4',\n",
    "    'wine_quality',\n",
    "    'letter_img',\n",
    "    'yeast_me2',\n",
    "    'webpage',\n",
    "    'ozone_level',\n",
    "    'mammography',\n",
    "    'protein_homo',\n",
    "    'abalone_19',\n",
    "]\n",
    "\n",
    "len(datasets_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli\n",
      "Counter({-1: 301, 1: 35})\n",
      "\n",
      "optical_digits\n",
      "Counter({-1: 5066, 1: 554})\n",
      "\n",
      "satimage\n",
      "Counter({-1: 5809, 1: 626})\n",
      "\n",
      "pen_digits\n",
      "Counter({-1: 9937, 1: 1055})\n",
      "\n",
      "abalone\n",
      "Counter({-1: 3786, 1: 391})\n",
      "\n",
      "sick_euthyroid\n",
      "Counter({-1: 2870, 1: 293})\n",
      "\n",
      "spectrometer\n",
      "Counter({-1: 486, 1: 45})\n",
      "\n",
      "car_eval_34\n",
      "Counter({-1: 1594, 1: 134})\n",
      "\n",
      "isolet\n",
      "Counter({-1: 7197, 1: 600})\n",
      "\n",
      "us_crime\n",
      "Counter({-1: 1844, 1: 150})\n",
      "\n",
      "yeast_ml8\n",
      "Counter({-1: 2239, 1: 178})\n",
      "\n",
      "scene\n",
      "Counter({-1: 2230, 1: 177})\n",
      "\n",
      "libras_move\n",
      "Counter({-1: 336, 1: 24})\n",
      "\n",
      "thyroid_sick\n",
      "Counter({-1: 3541, 1: 231})\n",
      "\n",
      "coil_2000\n",
      "Counter({-1: 9236, 1: 586})\n",
      "\n",
      "arrhythmia\n",
      "Counter({-1: 427, 1: 25})\n",
      "\n",
      "solar_flare_m0\n",
      "Counter({-1: 1321, 1: 68})\n",
      "\n",
      "oil\n",
      "Counter({-1: 896, 1: 41})\n",
      "\n",
      "car_eval_4\n",
      "Counter({-1: 1663, 1: 65})\n",
      "\n",
      "wine_quality\n",
      "Counter({-1: 4715, 1: 183})\n",
      "\n",
      "letter_img\n",
      "Counter({-1: 19266, 1: 734})\n",
      "\n",
      "yeast_me2\n",
      "Counter({-1: 1433, 1: 51})\n",
      "\n",
      "webpage\n",
      "Counter({-1: 33799, 1: 981})\n",
      "\n",
      "ozone_level\n",
      "Counter({-1: 2463, 1: 73})\n",
      "\n",
      "mammography\n",
      "Counter({-1: 10923, 1: 260})\n",
      "\n",
      "protein_homo\n",
      "Counter({-1: 144455, 1: 1296})\n",
      "\n",
      "abalone_19\n",
      "Counter({-1: 4145, 1: 32})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print class imbalance of each dataset\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "    data = fetch_datasets()[dataset]\n",
    "    print(dataset)\n",
    "    print(Counter(data.target))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "# with hyperparameter optimization\n",
    "\n",
    "def run_model(X_train, y_train, undersampler=None):\n",
    "\n",
    "    # set up the classifier\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, random_state=39, max_depth=3,\n",
    "    )\n",
    "\n",
    "    # set up a scaler\n",
    "    # (as the undersampling techniques use KNN\n",
    "    # we put the variables in the same scale)\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # without sampling:\n",
    "    if not undersampler:\n",
    "\n",
    "        model = rf\n",
    "\n",
    "        rf_params = {\n",
    "            \"n_estimators\": [10, 50, 100, 500],\n",
    "            \"max_depth\": [1, 2, 3, 4],\n",
    "        }\n",
    "\n",
    "    # set up a pipeline with sampling:\n",
    "    else:\n",
    "\n",
    "        # important to scale before the re-sampler\n",
    "        # as the many of methods require the variables in\n",
    "        # a similar scale\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", scaler),\n",
    "            (\"sampler\", undersampler),\n",
    "            (\"model\", rf),\n",
    "        ])\n",
    "\n",
    "        rf_params = {\n",
    "            \"model__n_estimators\": [10, 50, 100, 500],\n",
    "            \"model__max_depth\": [1, 2, 3, 4],\n",
    "        }\n",
    "\n",
    "    # When we make a pipeline and then run the training of the model\n",
    "    # with cross-validation, the procedure works as follows:\n",
    "\n",
    "    # 1) take 2 of the 3 fold as train set\n",
    "    # 2) resample the 2 fold (aka, the train set)\n",
    "    # 3) train the model on the resampled data from point 2\n",
    "    # 4) evaluate performance on the 3rd fold, that was not resampled\n",
    "\n",
    "    # this way, we make sure that we are not evaluating the performance\n",
    "    # of our classifier on the under-sampled data\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        rf_params,\n",
    "        random_state=0,\n",
    "        scoring=\"roc_auc\",\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print('Best parameters: {0}, \\n Best score: {1}'.format(\n",
    "        search.best_params_, search.best_score_))\n",
    "\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli\n",
      "Best parameters: {'n_estimators': 50, 'max_depth': 4}, \n",
      " Best score: 0.9220905923344948\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 500, 'model__max_depth': 2}, \n",
      " Best score: 0.9100813008130082\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 10, 'model__max_depth': 3}, \n",
      " Best score: 0.9369802555168409\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9331823461091755\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 3}, \n",
      " Best score: 0.9320789779326365\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 3}, \n",
      " Best score: 0.9234146341463415\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 500, 'model__max_depth': 2}, \n",
      " Best score: 0.925993031358885\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9212427409988386\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9245063879210221\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 1}, \n",
      " Best score: 0.5840882694541231\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 1}, \n",
      " Best score: 0.7096283391405342\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 3}, \n",
      " Best score: 0.7796747967479675\n",
      "\n",
      "\n",
      "optical_digits\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9826629268046189\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9792237113454588\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9879446472739813\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9828211199925245\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9792670207260844\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9823308866533491\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9816925311117828\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9824631924555376\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9815417033407104\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9487393377529667\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9548564430389709\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.8623299202419004\n",
      "\n",
      "\n",
      "satimage\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9305526354412228\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9290321453676219\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9174208637311969\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9297637832322471\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9298218226990844\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9282422573665882\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9261376156839282\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9259308961672884\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9283127263381206\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 500, 'model__max_depth': 2}, \n",
      " Best score: 0.721920730658251\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 1}, \n",
      " Best score: 0.7837568142828351\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 1}, \n",
      " Best score: 0.35440664564184343\n",
      "\n",
      "\n",
      "pen_digits\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9965886345207811\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9981261275741643\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9969149212479668\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9965541017611391\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9969840268151946\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9969406937442523\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9965516741064289\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9964852012289424\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9966983480438308\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9553978672930853\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9905585523316732\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9980301413541746\n",
      "\n",
      "\n",
      "abalone\n",
      "Best parameters: {'n_estimators': 50, 'max_depth': 4}, \n",
      " Best score: 0.8539019219699941\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 500, 'model__max_depth': 2}, \n",
      " Best score: 0.8505234777483469\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 3}, \n",
      " Best score: 0.8466942406049931\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.8545091207214593\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.8548930161235864\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 3}, \n",
      " Best score: 0.854979680780866\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.8522117039689459\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.8523472769560687\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 3}, \n",
      " Best score: 0.8550629779754455\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 10, 'model__max_depth': 3}, \n",
      " Best score: 0.21797813906460567\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 1}, \n",
      " Best score: 0.7665620860918523\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 1}, \n",
      " Best score: 0.21051353650589677\n",
      "\n",
      "\n",
      "sick_euthyroid\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9637921892469017\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9633867517631287\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9617555490205429\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9608298574130887\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9648219491646663\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9583153973729249\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9530834061898934\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9522807176503626\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9636440943797124\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9204144822945312\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 1}, \n",
      " Best score: 0.9160198209583156\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9498177870680931\n",
      "\n",
      "\n",
      "spectrometer\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9541128391655169\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.968881433170283\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9778941427317196\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9574794096743174\n",
      "\n",
      "oss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9589594046573854\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9671474559973243\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9673606756135289\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 3}, \n",
      " Best score: 0.9610936912078264\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9776401605418286\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.8892444291149296\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 3}, \n",
      " Best score: 0.712845959279234\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 500, 'model__max_depth': 2}, \n",
      " Best score: 0.9552238805970148\n",
      "\n",
      "\n",
      "car_eval_34\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9853270601765999\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9890118373287479\n",
      "\n",
      "cnn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9904144704062098\n",
      "\n",
      "tomek\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9852794589238417\n",
      "\n",
      "oss\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9873988853861111\n",
      "\n",
      "enn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9840287962994182\n",
      "\n",
      "renn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9834669352754082\n",
      "\n",
      "allknn\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9841703591002918\n",
      "\n",
      "ncr\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.984916233034005\n",
      "\n",
      "nm1\n",
      "Best parameters: {'model__n_estimators': 50, 'model__max_depth': 4}, \n",
      " Best score: 0.9943692260359418\n",
      "\n",
      "nm2\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9285904409753831\n",
      "\n",
      "iht\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9526436373070194\n",
      "\n",
      "\n",
      "isolet\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 4}, \n",
      " Best score: 0.9691857371333723\n",
      "\n",
      "random\n",
      "Best parameters: {'model__n_estimators': 100, 'model__max_depth': 4}, \n",
      " Best score: 0.9727492501890197\n",
      "\n",
      "cnn\n"
     ]
    }
   ],
   "source": [
    "# now we train several models, with the different under-samplers and\n",
    "# with cross-validation for each dataset\n",
    "\n",
    "# to store the results\n",
    "mean_dict = {}\n",
    "std_dict = {}\n",
    "\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "\n",
    "    # initiate a dictionary per dataset\n",
    "    mean_dict[dataset] = {}\n",
    "    std_dict[dataset] = {}\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    # load dataset\n",
    "    data = fetch_datasets()[dataset]\n",
    "\n",
    "    # separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.data,\n",
    "        data.target,\n",
    "        test_size=0.3,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # train model on data without re-sampling\n",
    "    # with cross-validation\n",
    "    search = run_model(X_train, y_train)\n",
    "\n",
    "    m, s = pd.DataFrame(search.cv_results_).sort_values(\n",
    "        by=\"mean_test_score\",\n",
    "        ascending=False).loc[0, [\"mean_test_score\", \"std_test_score\"]].values\n",
    "\n",
    "    # store results\n",
    "    mean_dict[dataset]['full_data'] = m\n",
    "    std_dict[dataset]['full_data'] = s\n",
    "\n",
    "    print()\n",
    "\n",
    "    for undersampler in undersampler_dict.keys():\n",
    "\n",
    "        print(undersampler)\n",
    "\n",
    "        # resample, train and evaluate performance\n",
    "        # with cross-validation\n",
    "        search = run_model(X_train, y_train, undersampler_dict[undersampler])\n",
    "\n",
    "        m, s = pd.DataFrame(search.cv_results_).sort_values(\n",
    "            by=\"mean_test_score\",\n",
    "            ascending=False).loc[0, [\"mean_test_score\", \"std_test_score\"]].values\n",
    "\n",
    "        # store results\n",
    "        mean_dict[dataset][undersampler] = m\n",
    "        std_dict[dataset][undersampler] = s\n",
    "        print()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the performance of the model in the \n",
    "# left out fold, that was not resampled, from the X_train\n",
    "\n",
    "for dataset in datasets_ls:\n",
    "    \n",
    "    mean_s = pd.Series(mean_dict[dataset])\n",
    "    std_s = pd.Series(std_dict[dataset])\n",
    "    \n",
    "    mean_s.plot.bar(yerr=[std_s, std_s]\n",
    "        )\n",
    "    plt.title(dataset)\n",
    "    plt.ylabel('Average ROC-AUC')\n",
    "    plt.axhline(mean_dict[dataset]['full_data'], color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Different under-sampling techniques work best for different datasets.**\n",
    "- ENN, RENN and AllKNN tend to produce similar results, so we may as well just choose one of the 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
